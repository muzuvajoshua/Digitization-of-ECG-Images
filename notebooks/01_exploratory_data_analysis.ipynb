{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECG Digitization - Exploratory Data Analysis\n",
    "\n",
    "This notebook explores the PhysioNet ECG Digitization competition data.\n",
    "\n",
    "## Goals:\n",
    "1. Understand the data structure\n",
    "2. Analyze image variations (segments)\n",
    "3. Examine ECG signal characteristics\n",
    "4. Identify challenges and opportunities\n",
    "5. Visualize sample data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src directory to path\n",
    "sys.path.append(str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from IPython.display import display\n",
    "\n",
    "# Project imports\n",
    "from config import *\n",
    "from data.dataloader import ECGDataLoader, get_data_statistics\n",
    "from utils.visualization import *\n",
    "from utils.metrics import calculate_snr, evaluate_single_lead\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview\n",
    "\n",
    "Let's start by understanding the structure of the competition data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if data exists\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "print(f\"Train CSV exists: {TRAIN_CSV.exists()}\")\n",
    "print(f\"Test CSV exists: {TEST_CSV.exists()}\")\n",
    "print(f\"\\nProject root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training metadata\n",
    "if TRAIN_CSV.exists():\n",
    "    train_df = pd.read_csv(TRAIN_CSV)\n",
    "    print(f\"Training records: {len(train_df)}\")\n",
    "    print(f\"\\nColumns: {train_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(train_df.head())\n",
    "    \n",
    "    print(f\"\\nDataset info:\")\n",
    "    train_df.info()\n",
    "else:\n",
    "    print(\"⚠️  Training data not found. Please download the competition data first.\")\n",
    "    print(\"\\nTo download data:\")\n",
    "    print(\"1. Install Kaggle API: pip install kaggle\")\n",
    "    print(\"2. Configure API credentials (kaggle.json)\")\n",
    "    print(\"3. Run: kaggle competitions download -c physionet-ecg-image-digitization\")\n",
    "    print(\"4. Extract to data/raw/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test metadata\n",
    "if TEST_CSV.exists():\n",
    "    test_df = pd.read_csv(TEST_CSV)\n",
    "    print(f\"Test records: {len(test_df)}\")\n",
    "    print(f\"\\nColumns: {test_df.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    display(test_df.head())\n",
    "else:\n",
    "    print(\"⚠️  Test data not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Sampling Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_CSV.exists():\n",
    "    # Analyze sampling frequencies\n",
    "    print(\"Sampling Frequency Distribution:\")\n",
    "    print(train_df['fs'].value_counts().sort_index())\n",
    "    \n",
    "    # Visualize\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Distribution\n",
    "    train_df['fs'].value_counts().sort_index().plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Sampling Frequency Distribution')\n",
    "    axes[0].set_xlabel('Sampling Frequency (Hz)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Statistics\n",
    "    axes[1].hist(train_df['fs'], bins=20, edgecolor='black')\n",
    "    axes[1].set_title('Sampling Frequency Histogram')\n",
    "    axes[1].set_xlabel('Sampling Frequency (Hz)')\n",
    "    axes[1].set_ylabel('Frequency')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(f\"  Mean: {train_df['fs'].mean():.2f} Hz\")\n",
    "    print(f\"  Median: {train_df['fs'].median():.2f} Hz\")\n",
    "    print(f\"  Min: {train_df['fs'].min():.2f} Hz\")\n",
    "    print(f\"  Max: {train_df['fs'].max():.2f} Hz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Signal Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_CSV.exists():\n",
    "    # Calculate expected signal lengths\n",
    "    train_df['expected_lead_II_length'] = train_df['fs'] * 10  # Lead II: 10 seconds\n",
    "    train_df['expected_other_length'] = train_df['fs'] * 2.5  # Other leads: 2.5 seconds\n",
    "    \n",
    "    print(\"Expected Signal Lengths:\")\n",
    "    print(f\"\\nLead II (10s):\")\n",
    "    print(train_df['expected_lead_II_length'].describe())\n",
    "    \n",
    "    print(f\"\\nOther Leads (2.5s):\")\n",
    "    print(train_df['expected_other_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Segment Analysis\n",
    "\n",
    "Training data contains multiple image variants for each ECG record. Let's explore these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image segment types\n",
    "print(\"Image Segments in Training Data:\")\n",
    "print(\"=\" * 60)\n",
    "for seg_id, description in IMAGE_SEGMENTS.items():\n",
    "    print(f\"  {seg_id}: {description}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader\n",
    "if TRAIN_DIR.exists():\n",
    "    train_loader = ECGDataLoader(mode='train')\n",
    "    print(f\"Training loader initialized with {len(train_loader)} records\")\n",
    "    \n",
    "    # Get first record ID\n",
    "    record_ids = train_loader.get_record_ids()\n",
    "    if record_ids:\n",
    "        sample_id = record_ids[0]\n",
    "        print(f\"\\nSample record ID: {sample_id}\")\n",
    "        \n",
    "        # Check available segments\n",
    "        segments = train_loader.get_available_segments(sample_id)\n",
    "        print(f\"Available segments: {segments}\")\n",
    "else:\n",
    "    print(\"⚠️  Training images not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Visualize Multiple Segments\n",
    "\n",
    "Let's visualize all image variants for a single ECG record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display multiple segments for one record\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    sample_id = record_ids[0]  # First record\n",
    "    fig = display_multiple_segments(sample_id, TRAIN_DIR)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Cannot display segments - data not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Image Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze image sizes for different segments\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    image_sizes = {}\n",
    "    \n",
    "    # Sample a few records\n",
    "    sample_records = record_ids[:10]\n",
    "    \n",
    "    for record_id in sample_records:\n",
    "        segments = train_loader.get_available_segments(record_id)\n",
    "        for segment in segments:\n",
    "            try:\n",
    "                image = train_loader.load_image(record_id, segment)\n",
    "                if segment not in image_sizes:\n",
    "                    image_sizes[segment] = []\n",
    "                image_sizes[segment].append(image.shape[:2])  # (height, width)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Image Sizes by Segment:\")\n",
    "    for segment, sizes in image_sizes.items():\n",
    "        unique_sizes = set(map(tuple, sizes))\n",
    "        print(f\"\\n  Segment {segment}:\")\n",
    "        for size in unique_sizes:\n",
    "            count = sizes.count(list(size))\n",
    "            print(f\"    {size[0]}x{size[1]} - {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ECG Signal Analysis\n",
    "\n",
    "Let's examine the time-series ECG data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a complete record (image + signals)\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    sample_id = record_ids[0]\n",
    "    record = train_loader.load_record(sample_id, segment='0001')\n",
    "    \n",
    "    print(f\"Record ID: {record['id']}\")\n",
    "    print(f\"Sampling Frequency: {record['fs']} Hz\")\n",
    "    print(f\"Image Shape: {record['image'].shape}\")\n",
    "    print(f\"\\nLeads:\")\n",
    "    for lead_name, signal in record['leads'].items():\n",
    "        print(f\"  {lead_name}: {len(signal)} samples, range [{signal.min():.3f}, {signal.max():.3f}] mV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Visualize ECG Signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all 12 leads\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    fig = plot_all_leads(\n",
    "        record['leads'],\n",
    "        record['fs'],\n",
    "        title=f\"12-Lead ECG - Record {sample_id}\"\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Signal Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistics for each lead\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    stats_list = []\n",
    "    \n",
    "    for lead_name, signal in record['leads'].items():\n",
    "        stats = {\n",
    "            'Lead': lead_name,\n",
    "            'Length': len(signal),\n",
    "            'Duration (s)': len(signal) / record['fs'],\n",
    "            'Mean (mV)': signal.mean(),\n",
    "            'Std (mV)': signal.std(),\n",
    "            'Min (mV)': signal.min(),\n",
    "            'Max (mV)': signal.max(),\n",
    "            'Range (mV)': signal.max() - signal.min()\n",
    "        }\n",
    "        stats_list.append(stats)\n",
    "    \n",
    "    stats_df = pd.DataFrame(stats_list)\n",
    "    display(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Image and Signal Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image with extracted signals\n",
    "if TRAIN_DIR.exists() and record_ids:\n",
    "    image_path = TRAIN_DIR / sample_id / f\"{sample_id}-0001.png\"\n",
    "    fig = plot_image_with_signals(\n",
    "        image_path,\n",
    "        record['leads'],\n",
    "        record['fs']\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test Set Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "if TEST_CSV.exists():\n",
    "    test_loader = ECGDataLoader(mode='test')\n",
    "    print(f\"Test records: {len(test_loader)}\")\n",
    "    \n",
    "    # Get first test record\n",
    "    test_ids = test_loader.get_record_ids()\n",
    "    if test_ids:\n",
    "        test_sample_id = test_ids[0]\n",
    "        test_record = test_loader.load_record(test_sample_id)\n",
    "        \n",
    "        print(f\"\\nSample Test Record: {test_sample_id}\")\n",
    "        print(f\"Image Shape: {test_record['image'].shape}\")\n",
    "        print(f\"Metadata: {test_record['metadata']}\")\n",
    "        \n",
    "        # Display test image\n",
    "        fig = display_ecg_image(\n",
    "            TEST_DIR / f\"{test_sample_id}.png\",\n",
    "            title=f\"Test ECG Image - {test_sample_id}\"\n",
    "        )\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Test data not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Submission Format Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sample submission\n",
    "if SAMPLE_SUBMISSION.exists():\n",
    "    sample_sub = pd.read_parquet(SAMPLE_SUBMISSION)\n",
    "    print(f\"Sample submission shape: {sample_sub.shape}\")\n",
    "    print(f\"\\nColumns: {sample_sub.columns.tolist()}\")\n",
    "    print(f\"\\nFirst rows:\")\n",
    "    display(sample_sub.head(20))\n",
    "    \n",
    "    # Parse IDs to understand format\n",
    "    sample_sub[['base_id', 'row_id', 'lead']] = sample_sub['id'].str.rsplit('_', n=2, expand=True)\n",
    "    sample_sub['row_id'] = sample_sub['row_id'].astype(int)\n",
    "    \n",
    "    print(f\"\\nLeads distribution:\")\n",
    "    print(sample_sub['lead'].value_counts())\n",
    "    \n",
    "    print(f\"\\nUnique base IDs: {sample_sub['base_id'].nunique()}\")\n",
    "else:\n",
    "    print(\"⚠️  Sample submission not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Key Findings and Next Steps\n",
    "\n",
    "### Summary:\n",
    "1. **Data Structure**: \n",
    "   - Training: Multiple image variants + time series\n",
    "   - Test: Single image per ECG\n",
    "   \n",
    "2. **Challenges**:\n",
    "   - Variable sampling frequencies\n",
    "   - Different image quality/artifacts\n",
    "   - Complex 12-lead layout\n",
    "   - Lead II has different duration (10s vs 2.5s)\n",
    "\n",
    "3. **Opportunities**:\n",
    "   - Multiple training variants help model robustness\n",
    "   - Clear evaluation metric (SNR)\n",
    "   - Standard ECG format\n",
    "\n",
    "### Next Steps:\n",
    "1. Develop image preprocessing pipeline\n",
    "2. Build baseline signal extraction model\n",
    "3. Implement evaluation metric testing\n",
    "4. Explore data augmentation strategies\n",
    "5. Research ECG digitization literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EDA Complete!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
